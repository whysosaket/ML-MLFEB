{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80374492-6c05-4479-bf31-3cd793abe355",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea541d7-cc13-48af-8788-56fff4442a9a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DATASET\n",
    "# https://archive.ics.uci.edu/ml/datasets/MAGIC+Gamma+Telescope\n",
    "\n",
    "    1.  fLength:  continuous  # major axis of ellipse [mm]\n",
    "    2.  fWidth:   continuous  # minor axis of ellipse [mm] \n",
    "    3.  fSize:    continuous  # 10-log of sum of content of all pixels [in #phot]\n",
    "    4.  fConc:    continuous  # ratio of sum of two highest pixels over fSize  [ratio]\n",
    "    5.  fConc1:   continuous  # ratio of highest pixel over fSize  [ratio]\n",
    "    6.  fAsym:    continuous  # distance from highest pixel to center, projected onto major axis [mm]\n",
    "    7.  fM3Long:  continuous  # 3rd root of third moment along major axis  [mm] \n",
    "    8.  fM3Trans: continuous  # 3rd root of third moment along minor axis  [mm]\n",
    "    9.  fAlpha:   continuous  # angle of major axis with vector to origin [deg]\n",
    "    10.  fDist:    continuous  # distance from origin to center of ellipse [mm]\n",
    "    11.  class:    g,h         # gamma (signal), hadron (background)\n",
    "\n",
    "    g = gamma (signal):     12332\n",
    "    h = hadron (background): 6688"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b03598b-a9e9-4ca3-9152-28adf9e3a1ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Making the columns as to be put into the data\n",
    "cols = ['fLength', 'fWidth', 'fSize', 'fConc', 'fConc1', 'fAsym', 'fM3Long', 'fM3Trans', 'fAlpha', 'fDist', 'class']\n",
    "# This is for reading the data\n",
    "df = pd.read_csv(\"magic04.data\", names=cols)\n",
    "# df.head() # returns the first five things\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1a2f0f-1d7e-4ec4-ab91-003a6455d4c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"class\"].unique() # returns all the unique data in data frame\n",
    "\n",
    "# now to convert this g,h to 0,1 (in order to understand the df)\n",
    "df[\"class\"] = (df[\"class\"] == \"g\").astype(int)\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea003a1-dd1a-4781-bb1f-4e11b76aca4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3c5da4-269b-47cb-8cde-8f24881d082f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for label in cols[:-1]:\n",
    "    plt.hist(df[df[\"class\"]==1][label], color='blue', label='gamma',  alpha=0.7,density=True)\n",
    "    plt.hist(df[df[\"class\"]==0][label], color='red', label='hadron',  alpha=0.7,density=True)\n",
    "    plt.title(label)\n",
    "    plt.ylabel(\"Probability\")\n",
    "    plt.xlabel(label)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3e167b-bc21-4cdd-afa5-86b366b4d2a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train, Validation, Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9799ca64-a113-4669-b892-40fcdc76b51c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting up the training data, validation data and the test data\n",
    "train, valid, test = np.split(df.sample(frac=1), [int(0.6*len(df)), int(0.8*len(df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36581440-fd45-4de9-98e3-23ce459c130c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Funtion responsible for sacling the dataset\n",
    "def scale_dataset(dataframe, oversample=False):\n",
    "    X = dataframe[dataframe.columns[:-1]].values #Upto the last column\n",
    "    Y = dataframe[dataframe.columns[-1]].values  #Only the last column\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    if oversample:\n",
    "        ros = RandomOverSampler()\n",
    "        X, Y = ros.fit_resample(X, Y)\n",
    "    \n",
    "    data = np.hstack((X, np.reshape(Y, (-1,1))))\n",
    "    \n",
    "    return data, X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9103c54-b81e-47be-98a8-d07d640c803a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(len(train[train[\"class\"]==1])) # Gamma\n",
    "# print(len(train[train[\"class\"]==0])) # Hadron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0cc3af-0f09-426e-9f41-ea7f81b0a8cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This will scale the dataset\n",
    "train, X_train, Y_train = scale_dataset(train, oversample=True)\n",
    "# Here we are not oversampling validation and test dataset as we need to be sure if our model can be trusted\n",
    "valid, X_valid, Y_valid = scale_dataset(valid, oversample=False)\n",
    "test, X_test, Y_test = scale_dataset(test, oversample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b22c2b-21b6-4952-9aa8-a93c7b15800b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sum(Y_test==0) # This shows no of input of a specific type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d26d04b-cbf3-41f3-9c15-ac2810b7b41d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1ac94d-42fd-4cf9-b764-31c8b5535590",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4988106-c914-4098-930f-5f9377150e6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Testing/Training the model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e42cb4-67d6-4c62-8f52-9ea60c470220",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Actually predicting the data\n",
    "Y_pred = knn_model.predict(X_test)\n",
    "print(Y_pred)\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8077258b-6694-4e14-926d-c3b8dac50481",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# printing the classification reports\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de416fe0-77ce-4a80-941b-426c151d6545",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bfce31-447c-479f-a10a-884ea87b02e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# importing naive bayes modules\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc46a5c2-c594-4e34-9417-139b3fe68732",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initializing and fitting the dataset into nb model\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858a4b5e-8976-4912-b890-d4d23d087452",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Actually predicting the data\n",
    "Y_pred = nb_model.predict(X_test)\n",
    "print(Y_pred)\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb4341c-b843-45cd-b42c-64ad747f8d2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# printing the classification reports\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9893e244-b4f5-4574-b9b6-ca4246955aa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076a6ec1-82aa-493b-9522-c7ec6e6001a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# importing logistic regression\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e029fdc-44c9-4759-a89a-d624661583e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initializing and fitting the dataset into nb model\n",
    "lg_model = LogisticRegression()\n",
    "lg_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa52c3f8-68d4-48b9-bad9-0c92bf2fc2a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Actually predicting the data\n",
    "Y_pred = lg_model.predict(X_test)\n",
    "print(Y_pred)\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356c42d9-0e52-4375-9a98-1826a967f1ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# printing the classification reports\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ea815e-9bb3-4bdb-a13e-fb94bc6b62b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SVM - Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f31124-3c14-4fd6-9843-3ac7a3042b3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# importing SVC\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010e695e-20e1-4823-af9f-3d3fd8ca6f27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initializing and fitting data into the SVC\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268163ba-cdfc-4947-a890-c8d61fe0b09e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Actually predicting the data\n",
    "Y_pred =svm_model.predict(X_test)\n",
    "print(Y_pred)\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d61f2fa-d86a-44b6-b8d5-6bad73cfa49b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# printing the classification reports\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577eb09c-b2ba-42f3-8137-b1102db73c08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Neural Networks - Using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e45768-e198-4ba7-9977-a2937b76d49b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# importing tensorflow\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0825bdd2-9f2d-4d31-9504-0073c2e82008",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "def plot_accuracy(history):\n",
    "    plt.plot(history.history['accuracy'], label='accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c798ed3f-bc07-4d83-9177-b27cf2323a24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nn_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(32, activation='relu', input_shape =(10,)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# here we are using 'sigmoid' activation function in the output layer as we know from the graph of sigmoid\n",
    "# that our output will be 0 or 1\n",
    "\n",
    "# in tensorflow we need to compile the tf data and we use can use any optimizer of our choice\n",
    "nn_model.compile(optimizer = tf.keras.optimizers.Adam(0.001), loss='binary_crossentropy',\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aac0ef-b8a3-4b97-bc9c-cbfa3070e7a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Actually this is training the model\n",
    "# we can set verbose = 0, in order to stop printing during the training\n",
    "history = nn_model.fit(X_train, Y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25e4b01-c087-45be-bd4b-f7da34051a69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_loss(history)\n",
    "plot_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd68a2e7-d7d0-4347-9b3e-70651d3a9ba1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we have above trained the model based only on one parameter of nodes\n",
    "# now we'll see and check it for a number of parameters\n",
    "\n",
    "def nn_train(X_train, Y_train, num_nodes, dropout_prob, lr, batch_size, epochs):\n",
    "    nn_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(num_nodes, activation='relu', input_shape =(10,)),\n",
    "        tf.keras.layers.Dropout(dropout_prob),\n",
    "        tf.keras.layers.Dense(num_nodes, activation='relu'),\n",
    "        tf.keras.layers.Dropout(dropout_prob),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    # here we are using 'sigmoid' activation function in the output layer as we know from the graph of sigmoid\n",
    "    # that our output will be 0 or 1\n",
    "\n",
    "    # in tensorflow we need to compile the tf data and we use can use any optimizer of our choice\n",
    "    nn_model.compile(optimizer = tf.keras.optimizers.Adam(lr), loss='binary_crossentropy',\n",
    "                     metrics=['accuracy'])\n",
    "    \n",
    "    # Actually this is training the model\n",
    "    # we can set verbose = 0, in order to stop printing during the training\n",
    "    history = nn_model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2, verbose=0)\n",
    "    return nn_model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f05af16-5ebb-47c8-a0b6-9a97a1fb9ecd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# defining a new show plotfunction in order to show all the plots inthe same graph\n",
    "# summarize history for accuracy\n",
    "def plot_graph(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(8,3))\n",
    "    ax1.plot(history.history['accuracy'], label='accuracy')\n",
    "    ax1.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "    ax1.set_ylabel('accuracy')\n",
    "    ax1.set_xlabel('epoch')\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    ax2.plot(history.history['loss'], label='loss')\n",
    "    ax2.plot(history.history['val_loss'], label='val_loss')\n",
    "    ax2.set_ylabel('loss')\n",
    "    ax2.set_xlabel('epoch')\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "plot_graph(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ad6f5c-1b94-4cc0-9ad5-384ae495c3a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we need to record which model has the least loss\n",
    "least_val_loss = float('inf')\n",
    "least_loss_model = None\n",
    "\n",
    "epochs = 100\n",
    "# setting up the loop to train the data\n",
    "for num_nodes in [16, 32, 64]:\n",
    "    for dropout_prob in [0, 0.2]:\n",
    "        for lr in [0.01, 0.005, 0.001]:\n",
    "            for batch_size in [32, 64, 128]:\n",
    "                print(f\"{num_nodes} nodes, dropout_prob {dropout_prob}, lr {lr}, batch_size {batch_size}\")\n",
    "                model, history = nn_train(X_train, Y_train, num_nodes, dropout_prob, lr, batch_size, epochs)\n",
    "                plot_graph(history)\n",
    "                results = model.evaluate(X_valid, Y_valid)\n",
    "                val_loss = results[0]  # Extract the loss value from the list\n",
    "                if val_loss < least_val_loss:\n",
    "                    least_val_loss = val_loss\n",
    "                    least_loss_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38ab607-d272-4b8d-9618-1e47d295b329",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = least_loss_model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5).astype(int).reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a1b8e1-0e7a-4206-81a2-5e3b137c8c68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# printing the classification reports\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
